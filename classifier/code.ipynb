{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from scipy import sparse\n",
    "from time import time\n",
    "\n",
    "# sklearn for feature extraction & modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('..', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "data = pd.read_json(data_dir / 'yelp_academic_dataset_review.json', lines=True)\n",
    "year = data.date.apply(lambda x: x.year)\n",
    "data.drop(['user_id', 'business_id', 'date'], axis=1, inplace=True)\n",
    "data['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "train = data[data.year < 2019]\n",
    "test = data[data.year == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "train.to_csv('../data/train.csv')\n",
    "test.to_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col=0)\n",
    "test = pd.read_csv('../data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Yelp review document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc_matrix(train, test=None, path='data'):\n",
    "    vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 2), max_features=10000)\n",
    "    train_dtm = vectorizer.fit_transform(train.text)\n",
    "    sparse.save_npz(path / 'train_dtm', train_dtm)\n",
    "    if test is not None:\n",
    "        test_dtm = vectorizer.transform(test.text)\n",
    "        sparse.save_npz(path / 'test_dtm', test_dtm)\n",
    "        return train_dtm, test_dtm\n",
    "    else:\n",
    "        return train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "train_dtm, test_dtm = create_doc_matrix(train, test, path=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload\n",
    "train_dtm = sparse.load_npz(data_dir / 'train_dtm.npz')\n",
    "test_dtm = sparse.load_npz(data_dir / 'test_dtm.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, runtime = {}, {}\n",
    "predictions = test[['stars']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5117779042568241"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_prediction = np.full_like(predictions.stars, fill_value=train.stars.mode().iloc[0])\n",
    "naive_benchmark = accuracy_score(predictions.stars, naive_prediction)\n",
    "naive_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, name, store=False):\n",
    "    start = time()\n",
    "    model.fit(X_train, train.stars)\n",
    "    runtime[name] = time() - start\n",
    "    predictions[name] = model.predict(X_test)\n",
    "    accuracy[name] = accuracy_score(test.stars, predictions[name])\n",
    "    if store:\n",
    "        joblib.dump(model, f'../results/{name}.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha is 100.0.\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "param_nb = {'alpha': np.logspace(-4, 4, 9)}\n",
    "clf_nb = GridSearchCV(nb, param_nb).fit(train_dtm, train.stars)\n",
    "print(f\"The best alpha is {clf_nb.best_params_['alpha']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Naive Bayes:  0.6557891031356202\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=clf_nb.best_params_['alpha'])\n",
    "result = 'nb_text'\n",
    "evaluate_model(nb, train_dtm, test_dtm, result, store=True)\n",
    "print(\"Multiclass Naive Bayes: \", accuracy[result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_text_accuracy = {}\n",
    "log_reg_text_runtime = []\n",
    "Cs = np.logspace(-4, 4, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.00010: 91.59s | 70.90%\n",
      "     0.00100: 141.64s | 73.96%\n",
      "     0.01000: 139.28s | 74.81%\n",
      "     0.10000: 140.92s | 74.78%\n",
      "     1.00000: 137.63s | 74.76%\n",
      "    10.00000: 140.12s | 74.74%\n",
      "   100.00000: 138.22s | 74.78%\n",
      "  1000.00000: 141.09s | 74.74%\n",
      " 10000.00000: 141.77s | 74.76%\n"
     ]
    }
   ],
   "source": [
    "for i, C in enumerate(Cs):\n",
    "    start = time()\n",
    "    model = LogisticRegression(C=C,\n",
    "                               multi_class='multinomial',\n",
    "                               solver='lbfgs')\n",
    "    \n",
    "    model.fit(train_dtm, train.stars)\n",
    "    log_reg_text_runtime.append(time() - start)\n",
    "    log_reg_text_accuracy[C] = accuracy_score(test.stars,\n",
    "                                              model.predict(test_dtm))\n",
    "\n",
    "    print(f'{C:12.5f}: {log_reg_text_runtime[i]:.2f}s | {log_reg_text_accuracy[C]:.2%}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy['lr_text'] = pd.Series(log_reg_text_accuracy).max()\n",
    "runtime['lr_text'] = np.mean(log_reg_text_runtime)\n",
    "lr_best = max(log_reg_text_accuracy, key=log_reg_text_accuracy.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', random_state=2021)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# online learning\n",
    "clf = SGDClassifier(loss='log', random_state=2021)\n",
    "classes = np.array(range(1,6))\n",
    "clf.fit(train_dtm, train.stars)\n",
    "pickle.dump(clf, open('../results/classifier.pkl', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(data=train_dtm.tocsr().astype(np.float32), \n",
    "                        label=train.stars.sub(1), \n",
    "                        categorical_feature=list(range(train_dtm.shape[1])))\n",
    "\n",
    "lgb_test = lgb.Dataset(data=test_dtm.tocsr().astype(np.float32), \n",
    "                       label=test.stars.sub(1), \n",
    "                       reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 56.096507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43360\n",
      "[LightGBM] [Info] Number of data points in the train set: 1701322, number of used features: 10000\n",
      "[LightGBM] [Info] Start training from score -1.871485\n",
      "[LightGBM] [Info] Start training from score -2.510575\n",
      "[LightGBM] [Info] Start training from score -2.208518\n",
      "[LightGBM] [Info] Start training from score -1.515108\n",
      "[LightGBM] [Info] Start training from score -0.831868\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[25]\ttraining's multi_error: 0.401738\tvalid_1's multi_error: 0.320236\n",
      "[50]\ttraining's multi_error: 0.371502\tvalid_1's multi_error: 0.298015\n",
      "[75]\ttraining's multi_error: 0.357112\tvalid_1's multi_error: 0.287366\n",
      "[100]\ttraining's multi_error: 0.34787\tvalid_1's multi_error: 0.28078\n",
      "[125]\ttraining's multi_error: 0.341596\tvalid_1's multi_error: 0.276105\n",
      "[150]\ttraining's multi_error: 0.336934\tvalid_1's multi_error: 0.272693\n",
      "[175]\ttraining's multi_error: 0.332912\tvalid_1's multi_error: 0.270088\n",
      "[200]\ttraining's multi_error: 0.329737\tvalid_1's multi_error: 0.268096\n",
      "[225]\ttraining's multi_error: 0.327011\tvalid_1's multi_error: 0.266449\n",
      "[250]\ttraining's multi_error: 0.324615\tvalid_1's multi_error: 0.265009\n",
      "[275]\ttraining's multi_error: 0.322448\tvalid_1's multi_error: 0.263781\n",
      "[300]\ttraining's multi_error: 0.320589\tvalid_1's multi_error: 0.262625\n",
      "[325]\ttraining's multi_error: 0.318991\tvalid_1's multi_error: 0.261912\n",
      "[350]\ttraining's multi_error: 0.31745\tvalid_1's multi_error: 0.261064\n",
      "[375]\ttraining's multi_error: 0.31584\tvalid_1's multi_error: 0.260283\n",
      "[400]\ttraining's multi_error: 0.314585\tvalid_1's multi_error: 0.259712\n",
      "[425]\ttraining's multi_error: 0.313169\tvalid_1's multi_error: 0.259159\n",
      "[450]\ttraining's multi_error: 0.311912\tvalid_1's multi_error: 0.258579\n",
      "[475]\ttraining's multi_error: 0.310664\tvalid_1's multi_error: 0.258054\n",
      "[500]\ttraining's multi_error: 0.30957\tvalid_1's multi_error: 0.25772\n",
      "[525]\ttraining's multi_error: 0.30842\tvalid_1's multi_error: 0.257247\n",
      "[550]\ttraining's multi_error: 0.307328\tvalid_1's multi_error: 0.256896\n",
      "[575]\ttraining's multi_error: 0.306252\tvalid_1's multi_error: 0.256529\n",
      "[600]\ttraining's multi_error: 0.305268\tvalid_1's multi_error: 0.25632\n",
      "[625]\ttraining's multi_error: 0.304335\tvalid_1's multi_error: 0.256043\n",
      "[650]\ttraining's multi_error: 0.303352\tvalid_1's multi_error: 0.255834\n",
      "[675]\ttraining's multi_error: 0.30243\tvalid_1's multi_error: 0.255592\n",
      "[700]\ttraining's multi_error: 0.301494\tvalid_1's multi_error: 0.255335\n",
      "[725]\ttraining's multi_error: 0.300556\tvalid_1's multi_error: 0.255205\n",
      "[750]\ttraining's multi_error: 0.299715\tvalid_1's multi_error: 0.255113\n",
      "[775]\ttraining's multi_error: 0.298819\tvalid_1's multi_error: 0.254992\n",
      "[800]\ttraining's multi_error: 0.297951\tvalid_1's multi_error: 0.254881\n",
      "[825]\ttraining's multi_error: 0.297148\tvalid_1's multi_error: 0.254771\n",
      "[850]\ttraining's multi_error: 0.296389\tvalid_1's multi_error: 0.254648\n",
      "[875]\ttraining's multi_error: 0.295468\tvalid_1's multi_error: 0.254487\n",
      "[900]\ttraining's multi_error: 0.294654\tvalid_1's multi_error: 0.254418\n",
      "[925]\ttraining's multi_error: 0.293861\tvalid_1's multi_error: 0.254296\n",
      "[950]\ttraining's multi_error: 0.29307\tvalid_1's multi_error: 0.254222\n",
      "[975]\ttraining's multi_error: 0.29227\tvalid_1's multi_error: 0.254189\n",
      "[1000]\ttraining's multi_error: 0.291426\tvalid_1's multi_error: 0.254126\n",
      "[1025]\ttraining's multi_error: 0.290667\tvalid_1's multi_error: 0.254115\n",
      "Early stopping, best iteration is:\n",
      "[1019]\ttraining's multi_error: 0.290843\tvalid_1's multi_error: 0.254077\n"
     ]
    }
   ],
   "source": [
    "param = {'objective': 'multiclass',\n",
    "         'metrics': ['multi_error'],\n",
    "         'num_class': 5}\n",
    "booster = lgb.train(params=param,\n",
    "                    train_set=lgb_train,\n",
    "                    num_boost_round=2000,\n",
    "                    early_stopping_rounds=25,\n",
    "                    valid_sets=[lgb_train, lgb_test],\n",
    "                    verbose_eval=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '../results/reviews.sqlite'\n",
    "document = \"The food is good!\"\n",
    "y = 5\n",
    "if os.path.exists(db_path):\n",
    "    os.remove(db_path)\n",
    "conn = sqlite3.connect(db_path)\n",
    "c = conn.cursor()\n",
    "c.execute(\n",
    "    \"CREATE TABLE review_db \"\\\n",
    "    \"(review TEXT, star INTEGER, date TEXT)\"\n",
    ")\n",
    "c.execute(\n",
    "    \"INSERT INTO review_db (review, star, date) \"\\\n",
    "    \"VALUES (?, ?, DATETIME('now'))\", (document, y))\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The food is good!', 5, '2021-03-16 13:39:08')]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "c = conn.cursor()\n",
    "c.execute(\n",
    "    \"SELECT * FROM review_db\"\n",
    ")\n",
    "results = c.fetchall()\n",
    "conn.close()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer & Hashingvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub(r'[\\W]+', ' ', text.lower()) +        ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "pickle.dump(stop, open(os.path.join('../results/stopwords.pkl'),'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = HashingVectorizer(decode_error='ignore', n_features=2**21, preprocessor=None, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dtm = vect.transform(train.text)\n",
    "test_dtm = vect.transform(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', random_state=2021)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log', random_state=2021)\n",
    "classes = np.array(range(1,6))\n",
    "clf.fit(train_dtm, train.stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('../results/classifier_hash.pkl', 'wb'), protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
